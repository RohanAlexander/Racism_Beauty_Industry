---
title: "The Shades of Racism in the Beauty Industry"
subtitle: "An exploration of inclusivity and tokenism within fashion and makeup"
author: 
  - Huda Sahaf
thanks: "Code and data are available at: https://github.com/hsahaf/Racism_Beauty_Industry.git."
date: "`r Sys.time()`"
date-format: "D MMMM YYYY"
abstract: "This paper aims to investigate the history of racism in the beauty industry and how this impacts the inclusivity in the market. The complexions of models are assigned a lightness value and analyzed across 8 years. These results are compared to the foundation shade ranges across all major makeup brands across the U.S revealing a continuation of compounding racism within the industry as a whole."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(janitor)
library(dplyr)
library(ggplot2)
library(kableExtra)
library(knitr)
library(readr)
library(RColorBrewer)
library(scales)
```

```{r}
fashion_tones <-
  read.csv(
    file = "https://raw.githubusercontent.com/the-pudding/data/master/vogue/faces.csv", 
    skip = 0 
  )

fashion_frequency <-
  read.csv(
    file = "https://raw.githubusercontent.com/the-pudding/data/master/vogue/models.csv", 
    skip = 0 
  )

makeup_shades <-
  read.csv(
    file = "https://raw.githubusercontent.com/the-pudding/data/master/makeup-shades/shades.csv", 
    skip = 0 
  )

#### Save data ####

write_csv(fashion_tones, here::here("inputs/data/fashion_tones.csv")) 

write_csv(fashion_frequency, here::here("inputs/data/fashion_frequency.csv")) 

write_csv(makeup_shades, here::here("inputs/data/makeup_shades.csv")) 
         
```

```{r}

### Clean Fashion Tones Dataset: 
cleaned_fashion_tones <-
  clean_names(fashion_tones)

cleaned_fashion_tones <-
  cleaned_fashion_tones |>
  rename(
    skintone = tone,
    lightness_value = l
  )
head(cleaned_fashion_tones)
```


```{r}
#| include: false
#| warning: false
#| echo: false
#| message: false

### Simplifying Dates: Fashion Tones Dataset:
cleaned_fashion_tones<-
  cleaned_fashion_tones |>
  separate(
    col = date,
    into = c("Month", "Day", "Year"),
    sep = "/"
  ) |>
  mutate(cleaned_fashion_tones, clean_date = paste(Year, Month, Day, sep = "-"))
  str(cleaned_fashion_tones$clean_date)

```

```{r}
#| include: false
#| warning: false
#| echo: false
#| message: false

### Clean Fashion Frequency Data Set: 
cleaned_fashion_frequency<-
  clean_names(fashion_frequency)

cleaned_fashion_frequency <-
  cleaned_fashion_frequency |>
  rename(
    skintone = tone,
    lightness_value = l,
    num_covers = n_covers
  )

```

```{r}
#| include: false
#| warning: false
#| echo: false
#| message: false

### Clean Makeup Shades Data Set:
cleaned_makeup_shades <-
  clean_names(makeup_shades)

cleaned_makeup_shades<-
  cleaned_makeup_shades |>
  rename(
    hue = h,
    lightness = l,
    saturation = s,
    value = v,
    hex_code = hex
  )|>
  mutate(lightness_value = lightness/100)

cleaned_makeup_shades<-
  cleaned_makeup_shades |>
  filter(group == 0|group == 1|group == 2|group == 3|group == 4)
  
```

```{r}
#| label: fig-fullspread
#| fig-cap: Complexion Values of All Models on Vogue Covers from 2000-2018
### Modeling Full Spread of Complexion Values on Vogue Covers from 2000-2018
cleaned_fashion_tones$clean_date <- ymd(cleaned_fashion_tones$clean_date)

entire_spread <- cleaned_fashion_tones |>
  ggplot(aes(x = lightness_value, y = clean_date)) +
  geom_point(aes(color = lightness_value < 0.4)) + 
  labs(
    x = "Lightness Value of Vogue Models",
    y = "Date of Cover",
    title = "Complexions of Models on Covers of Vogue: 2000-2018"
  ) +
  theme_classic()
  
datebreaks <- seq(as.Date("2001-01-01"), as.Date("2018-09-01"), by = "1 year") 
  
print(entire_spread)
```

@fig-fullspread is a graph of the lightness value of every model that has been on the cover of Vogue from 2000 to 2018. Lightness value is 

```{r}
#| message: false
#| warning: false
#| echo: false
#| tbl-cap: "Models With More than 5 Appearances on Vogue"
#| label: tbl-appearances
### Table 1: All Models With More than 5 Appearances on Vogue 
cleaned_fashion_frequency |>
  select(model, num_covers, lightness_value) |>
  group_by(num_covers) |>
  filter(num_covers > 4) |>
  kable(
    col.names = c(
      "Model",
      "Number of Covers", 
      "Lightness Value"
    ),
    digits = 2
  )

```

```{r}
#| warning: false
#| echo: false
#| label: fig-whitewashing
#| fig-cap: Rihanna's Appearances on Vogue
### Graph 2: Case Study: Rihanna's 5 Appearances and the respective Complexion Values:
cleaned_fashion_tones|>
  group_by(model)|>
  filter(model=="Rihanna")|>
  ggplot(mapping = aes(x = Year, y = lightness_value, color = model)) +
  geom_point()+
  labs(
    title = "Rihanna: A Case Study in White-Washing",
    y = "Complexion Value",
    color = "Model"
  )

  
```


```{r}
#| warning: false
#| echo: false
#| label: fig-deepest
#| fig-cap: Top 4 Deepest Complexion Models on Vogue
### Graph 3: The Top 4 Deepest Complexion Models on Vogue
cleaned_fashion_tones|>
  filter(model== "Lupita Nyongo" | model=="Rihanna"| model == "Michelle Obama" | model == "Serena Williams") |>
  ggplot(aes(y = lightness_value, color = model)) +
  geom_boxplot() +
  theme_light() +
  labs(
    y = "Lightness Value of Skintone",
    title = "Appearances of Deepest Complexion Models on Vogue"
  )
```

```{r}
#| warning: false
#| echo: false
#| label: fig-all_white
#| fig-cap: Models with Highest Number of Appearances
### Graph 4: Models with the Highest Number of Appearances on Vogue and their respective Complexion Values
cleaned_fashion_tones|>
  filter(model== "Nicole Kidman" | model=="Gisele Bundchen"| model == "Charlize Theron" | model == "Sarah Jessica Parker") |>
  ggplot(aes(y = lightness_value, color = model)) +
  geom_boxplot() +
  theme_light() +
  labs(
    y = "Lightness Value of Skintone",
    title = "Complexions of Models with Highest Number of Vogue Covers" 
  )

```


```{r}
#| message: false
#| warning: false
#| echo: false
#| tbl-cap: "US Makeup Brands: Foundation Shade Range"
#| label: tbl-shades

### Table 2: All US Brands and Their Number of Foundation Shades
cleaned_makeup_shades|>
  select(brand, product, lightness_value)|>
  group_by(brand) |>
  summarise(total_shades = n()) |>
  kable(
    col.names = c(
      "Makeup Brand",
      "Number of Foundation Shades"
      )
  )

```



```{r}
#| warning: false
#| echo: false
#| label: fig-bestsellers
#| fig-cap: The Shade Distribution of Best-Selling Foundations in the U.S
### Graph 5: US Bestseller Foundations and Their Inclusivity 
cleaned_makeup_shades|>
  filter(group == 2)|>
  group_by(brand)|>
  ggplot(aes(x = lightness_value, color = brand)) +
  stat_ecdf(geom = "point") +
  theme_classic()

```

```{r}
#| warning: false
#| echo: false
#| label: fig-bipoc
#| fig-cap: The Shade Distribution of BiPOC-owned Makeup Brands
### Graph 5: BiPOC Reccs of Brands with BiPOC Founder Bestseller Foundations and Their Inclusivity 
cleaned_makeup_shades|>
  filter(group == 3)|>
  group_by(brand)|>
  ggplot(aes(x = lightness_value, color = brand)) +
  stat_ecdf(geom = "point") +
  theme_classic()
```


```{r}
#| warning: false
#| echo: false
#| label: fig-bigboys
#| fig-cap: The Shade Distribution of Largest Shade Ranges Offered in the U.S
### Graph Range of Shades With Brands with Largest Shade Ranges
cleaned_makeup_shades|>
  filter(brand == "Beauty Bakerie"|brand == "Bobbi Brown" |brand == "bareMinerals" |brand == "Bobbi Brown" | brand == "MAC"| brand == "Maybelline"|brand == "Estée Lauder"|brand == "Fenty"|brand == "Lancôme"|brand == "Make Up For Ever")|> 
  ggplot(cleaned_makeup_shades, mapping = aes(x = brand, y = lightness_value)) + 
  geom_boxplot() +
  geom_jitter(alpha = 0.3, width = 0.15, height = 0) +
  theme_minimal()
  
```


# Introduction


You can and should cross-reference sections and sub-sections. For instance, @sec-data and @sec-first-point. 



# Data {#sec-data}
## Data Management
All analysis on the data sets were done using R [@citeR]. The data was read in, cleaned, and manipulated using `dplyr`[@dan], `tidyverse` [@tidy], and `janitor` [@janice]. The graphs and tables in this paper were coded using the following packages: `ggplot2` [@gabe], `kableExtra`[@kev], `knitr` [@nat], `readr` [@ron], and `RColorBrewer`[@ryan].

## Source and Sampling
In order to conduct an analysis on the various parts of the beauty industry, three separate data sets were used. The Pudding is a digital publication that makes its data sets open to the public @pudd. A closer look is taken at Vogue using the first two data sets used for the article *Colorism in High Fashion* [@high_f]. All covers of Vogue from the year 2000 to 2018 are analyzed and categorized in these data sets. The female models on each cover are identified, and then their skin tones are filtered out of the cover, and an average color value is assigned based on the all skin tone pixels. These color values are then drained of any hue or saturation and therefore assigned a lightness value based on how light or deep the complexion of the model is, which allows for the comparison of all models on the covers of Vogue over the span of 8 years. The first data set contains the name of the model, date of their appearance on Vogue, the hex code of their skin tone, and their lightness value once the hue and saturation has been removed. This includes multiple appearances of the same model. The second data set contains the names of the models, the hex code of their skin tone, the number of covers they have made appearances in, and their average lightness value across these appearances.

The data set behind The Pudding article, *Beauty Brawl* is the third data set used in this paper [@bbshades]. It contains data about the foundation shade ranges through lightness values of multiple beauty brands around the world. For the sake of this paper, we are focusing on beauty retailers based in the US, especially since Vogue is also based in the United States. 


Our data is of penguins (@fig-bills).

```{r}
#| label: fig-bills
#| fig-cap: Bills of penguins
#| echo: false
```

Talk more about it.

Also bills and their average (@fig-billssssss). (You can change the height and width, but don't worry about doing that until you have finished every other aspect of the paper - Quarto will try to make it look nice and the defaults usually work.)


Talk way more about it. 

Here's a dumb example of how to use some references: In paper we run our analysis in `R` [@citeR]. We also use the `tidyverse` which was written by @thereferencecanbewhatever If we were interested in baseball data then @citeLahman could be useful. 

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results

# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional details


\newpage


# References


